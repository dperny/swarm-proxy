package main

import (
	"bytes"
	"context"
	"os"
	"os/signal"
	"syscall"
	"text/template"

	"github.com/pkg/errors"

	"github.com/docker/docker/api/types"
	"github.com/docker/docker/api/types/events"
	"github.com/docker/docker/api/types/filters"
	"github.com/docker/docker/api/types/swarm"
	"github.com/docker/docker/client"

	log "github.com/sirupsen/logrus"
)

// TODO LIST:
// * support generic templates (allows using any reverse proxy)
// * reconcile the proxy state when the manager comes up by checking that
//	 all the configs are in the right place
// * support updates
// * support configuring/changing default values
// * optimize by caching
// * auto-generate proxy service and network, instead of relying on them
//   already existing.
// * allow non-standard ports; right now we default to port 80
// * batch updates to the proxy, so that creating a lot of services in a short
//   time period is done more efficiently
// * handle more errors and edge cases
// * write Dockerfile

// I'm cheating and baking this templating into the file because then it gets
// compiled into the binary. In a more complete and less proof-of-concept
// implementation, we would read this template from a file (which the user
// could customize in a child image!)
const nginxConfigTemplate = `server {
	# This config file was generated by ProxyManager
	server_name {{.ServerName}};
	{{/* TODO(dperny): what to do w/ access_log directive? */}}
	location / {
		proxy_pass http://{{.ServiceName}};
	}
}`

const (
	configServerNameLabel = "proxymanager_config_server_name"

	defaultConfigFilePrefix = "proxymanager_config_"
	defaultProxyService     = "proxy"
	defaultProxyNetwork     = "proxynet"
	nginxConfigLocation     = "/etc/nginx/conf.d/"
	configServiceIDLabel    = "proxyServiceId"
)

type ServerConfig struct {
	ServerName  string // the domain name to respond as
	ServiceName string // the name of the service responding
}

// ProxyManager is a struct that holds data for the proxy manager
type ProxyManager struct {
	Cli            *client.Client
	ProxyService   string // the name of the service acting as the proxy
	ProxyNetwork   string // the network that proxied services are connected to
	ConfigTemplate *template.Template
	proxyNwId      string // the ID of the proxy network
}

func NewProxyManager() (*ProxyManager, error) {
	t := template.Must(template.New("config").Parse(nginxConfigTemplate))
	cli, err := client.NewEnvClient()
	if err != nil {
		return nil, err
	}
	return &ProxyManager{
		Cli:            cli,
		ProxyService:   defaultProxyService,
		ProxyNetwork:   defaultProxyNetwork,
		ConfigTemplate: t,
	}, nil
}

func (p *ProxyManager) IsServiceManaged(service swarm.Service) bool {
	log.Debugf("Checking if service has nw %v", p.ProxyNetwork)
	managed := false
	for _, network := range service.Spec.TaskTemplate.Networks {
		if network.Target == p.ProxyNetwork {
			log.Debugf("Service has nw %v", network.Target)
			managed = true
			break
		}
	}
	return managed
}

func (p *ProxyManager) CreateConfig(ctx context.Context, service swarm.Service) error {
	log.Debug("Creating config for service")
	// Generate the service config
	// set the server name to be the service name
	serverConfig := ServerConfig{
		ServerName:  service.Spec.Name,
		ServiceName: service.Spec.Name,
	}

	// if the override is set, use it as the name instead of the server name
	if name, ok := service.Spec.Labels[configServerNameLabel]; ok {
		log.Debugf("Overriding service server name with %v", name)
		serverConfig.ServerName = name
	}

	// create a buffer to hold the generated config
	buf := &bytes.Buffer{}
	err := p.ConfigTemplate.Execute(buf, serverConfig)
	log.Debug(buf.String())
	// then create a config spec with the newly created config
	configSpec := swarm.ConfigSpec{
		Annotations: swarm.Annotations{
			Name: defaultConfigFilePrefix + serverConfig.ServiceName,
			Labels: map[string]string{
				// add the ID of this managed service to the config's labels
				// helps with removals later
				configServiceIDLabel: service.ID,
			},
		},
		Data: buf.Bytes(),
	}
	// create the config
	log.Debugf("Creating new config %v", configSpec.Name)
	resp, err := p.Cli.ConfigCreate(ctx, configSpec)
	if err != nil {
		return err
	}

	// create the config reference
	ref := &swarm.ConfigReference{
		File: &swarm.ConfigReferenceFileTarget{
			Name: nginxConfigLocation + configSpec.Name + ".conf",
			// we have to set UID and GID. they're unset, this will fail.
			// unsure why sensible defaults aren't assumed.
			UID:  "0",
			GID:  "0",
			Mode: 444,
		},
		ConfigID:   resp.ID,
		ConfigName: configSpec.Name,
	}

	log.Debug("Updating proxy service")
	// now update the proxy service to include this config
	proxy, _, err := p.Cli.ServiceInspectWithRaw(ctx, p.ProxyService, types.ServiceInspectOptions{})
	if err != nil {
		return err
	}
	// add the config to the service's configs
	proxy.Spec.TaskTemplate.ContainerSpec.Configs = append(proxy.Spec.TaskTemplate.ContainerSpec.Configs, ref)
	_, err = p.Cli.ServiceUpdate(ctx, proxy.ID, proxy.Version, proxy.Spec, types.ServiceUpdateOptions{})
	if err != nil {
		return err
	}
	log.Infof("Added config for %v", service.ID)
	return nil
}

// RemoveConfig handles events where a proxied service is removed.
func (p *ProxyManager) RemoveConfig(ctx context.Context, actor events.Actor) error {
	log.Debug("Checking for remove")
	// this function is kinda tricky because we only have the ID of the removed
	// service, because it's removed.

	// get the id of the service. this is just for programmer clarity, in case
	// the implementation of this function changes later
	serviceID := actor.ID

	// First, list all configs
	configs, err := p.Cli.ConfigList(ctx, types.ConfigListOptions{})
	if err != nil {
		return err
	}

	for _, config := range configs {
		if id := config.Spec.Labels[configServiceIDLabel]; id == serviceID {
			log.Debugf("Found config for %v", serviceID)
			// we found a config for this service
			// get the proxy service and remove this config from it
			service, _, err := p.Cli.ServiceInspectWithRaw(ctx, p.ProxyService, types.ServiceInspectOptions{})
			if err != nil {
				return err
			}
			// `i` is the location of the config in the proxy service's
			// config references. if it's still -1 after this loop, that means
			// the proxy service doesn't have this config
			i := -1
			// take the configs array as a variable so we don't have to type the whole chain
			refs := service.Spec.TaskTemplate.ContainerSpec.Configs
			for j, configRef := range refs {
				if configRef.ConfigID == config.ID {
					i = j
				}
			}
			if i >= 0 {
				log.Debug("Removing config from proxy")
				// from github.com/golang/go/wiki/SliceTricks
				// delete without preserving order (memory safe)
				// replace the target element with the last element
				refs[i] = refs[len(refs)-1]
				// nil the last element
				refs[len(refs)-1] = nil
				// cut of the last element
				refs = refs[:len(refs)-1]
				// now update the service
				service.Spec.TaskTemplate.ContainerSpec.Configs = refs
				_, err = p.Cli.ServiceUpdate(ctx, service.ID, service.Version, service.Spec, types.ServiceUpdateOptions{})
				if err != nil {
					// TODO(dperny) handle case where the service has been updated
					// in the meantime and the version is old
					return err
				}
			} else {
				log.Infof("A config for service %v exists, but is not in the proxy's configs")
			}
			// now delete the old config
			// TODO(dperny) what happens if we try to remove the config while
			// the service update removing the config is in progress?
			log.Infof("Removing config %v", config.Spec.Name)
			err = p.Cli.ConfigRemove(ctx, config.ID)
			if err != nil {
				return err
			}
			return nil
		}
	}

	log.Infof("Service %v had no config to remove", serviceID)
	return nil
}

func (p *ProxyManager) HandleEvent(ctx context.Context, event events.Message) {
	// check that the service belongs to our network and is managed by us
	var err error
	switch event.Action {
	case "create":
		var service swarm.Service
		service, _, err = p.Cli.ServiceInspectWithRaw(ctx, event.Actor.ID, types.ServiceInspectOptions{})
		if err != nil {
			break
		}
		if !p.IsServiceManaged(service) {
			// TODO(dperny) log that we passed
			log.Infof("Service %v is not managed", service.Spec.Name)
			break
		}
		err = p.CreateConfig(ctx, service)
	case "update":
		err = errors.New("service updates not supported")
	case "remove":
		err = p.RemoveConfig(ctx, event.Actor)
	}
	if err != nil {
		log.Warnf("Event handling error: %v", err)
	}
}

// Reconcile checks the cluster state to see if all services are wired up
// correctly. It's called once at the start of the program.
func (p *ProxyManager) Reconcile(ctx context.Context) error {
	log.Info("Reconciling proxy configs with cluster state")
	log.Error("Reconciling not implemented!")
	// TODO(dperny) implement
	return nil
}

func (p *ProxyManager) Run(ctx context.Context) error {
	// replace the network name with id
	nw, err := p.Cli.NetworkInspect(ctx, p.ProxyNetwork, false)
	if err != nil {
		return err
	}
	log.Debugf("Setting ProxyNetwork to %v", nw.ID)
	p.ProxyNetwork = nw.ID
	// Reconcile our current state
	if err := p.Reconcile(ctx); err != nil {
		return err
	}

	// subscribe to service events
	filter := filters.NewArgs()
	filter.Add("type", events.ServiceEventType)
	opts := types.EventsOptions{Filters: filter}
	log.Debug("Subscribing to Docker events")
	events, errors := p.Cli.Events(ctx, opts)

	for {
		select {
		case <-ctx.Done():
			// TODO(dperny) check if I need to perform any cleanup
			log.Debug("Context done, returning")
			return nil
			// handle context done
		case event := <-events:
			// handle events
			log.Debug("Recieved Docker event, calling handler")
			// TODO(dperny) Can I safely do HandleEvent async?
			p.HandleEvent(ctx, event)
		case err := <-errors:
			log.Error("Recieved event stream error")
			// TODO(dperny) Restart event stream
			return err
			// handle event stream errors
		}
	}
}

func main() {
	log.SetLevel(log.DebugLevel)
	log.Info("Running main function")
	ctx, cancel := context.WithCancel(context.Background())
	log.Info("Registering Signal Handlers")
	ch := make(chan os.Signal, 1)
	signal.Notify(ch, syscall.SIGINT, syscall.SIGTERM, os.Interrupt)
	defer func() {
		signal.Stop(ch)
		cancel()
	}()

	go func() {
		select {
		case <-ch:
			log.Info("Recieved signal, canceling context")
			cancel()
		case <-ctx.Done():
		}
	}()

	p, err := NewProxyManager()
	if err != nil {
		log.Fatal(err.Error())
	}

	if err := p.Run(ctx); err != nil {
		log.Fatal(err.Error())
	}
	log.Info("Exited cleanly")
}
